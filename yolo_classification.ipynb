{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPT 图像分类训练与推理\n",
        "\n",
        "本 Notebook 使用 `archive/train` 与 `archive/valid` 中的 YOLO 格式钢板缺陷图像，构建端到端的分类训练与推理流程。\n",
        "\n",
        "主要步骤：\n",
        "- 读取 YOLO 标注并整理成分类数据索引\n",
        "- 构建 PyTorch Dataset 与 DataLoader\n",
        "- 微调预训练 ResNet50 分类模型\n",
        "- 保存最优权重并提供单张图片推理函数\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. 准备环境\n",
        "\n",
        "首次运行前请安装依赖（根据实际 CUDA 版本调整 PyTorch 安装命令）。已安装的环境可直接跳过此步骤。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fdbbfe3",
      "metadata": {},
      "outputs": [],
      "source": [
        "!curl -L -o ./neu-yolo.zip https://www.kaggle.com/api/v1/datasets/download/zymzym/neu-yolo\n",
        "!unzip -q neu-yolo.zip\n",
        "!rm neu-yolo.zip\n",
        "# 如已安装依赖，可跳过此步骤\n",
        "# !pip install --upgrade pip\n",
        "# CPU 环境示例: !pip install torch torchvision torchaudio\n",
        "# GPU 环境示例: !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# !pip install numpy pandas matplotlib seaborn scikit-learn tqdm Pillow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471d1f64",
      "metadata": {},
      "source": [
        "## 1. 导入库\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "51c50855",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zhaizeyu/Documents/vscode/github/test/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from collections import Counter, defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56c48550",
      "metadata": {},
      "source": [
        "## 2. 基础配置与随机种子\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "80e52bcc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n",
            "train images: 1770 | labels: 1770\n",
            "valid images: 30 | labels: 30\n",
            "Checkpoint dir: /Users/zhaizeyu/Documents/vscode/archive/checkpoints\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {DEVICE}')\n",
        "\n",
        "BASE_DIR = Path.cwd()\n",
        "if not (BASE_DIR / 'train').exists():\n",
        "    candidate = BASE_DIR / 'archive'\n",
        "    if candidate.exists():\n",
        "        BASE_DIR = candidate\n",
        "\n",
        "TRAIN_ROOT = BASE_DIR / 'train' / 'train'\n",
        "VALID_ROOT = BASE_DIR / 'valid' / 'valid'\n",
        "for name, root in {'train': TRAIN_ROOT, 'valid': VALID_ROOT}.items():\n",
        "    images_dir = root / 'images'\n",
        "    labels_dir = root / 'labels'\n",
        "    if not images_dir.exists():\n",
        "        raise FileNotFoundError(f'未找到 {images_dir}，请确认 notebook 的工作路径。')\n",
        "    if not labels_dir.exists():\n",
        "        raise FileNotFoundError(f'未找到 {labels_dir}，请确认 YOLO 标签是否存在。')\n",
        "    num_images = len(list(images_dir.glob('*')))\n",
        "    num_labels = len(list(labels_dir.glob('*.txt')))\n",
        "    print(f\"{name:<5} images: {num_images} | labels: {num_labels}\")\n",
        "\n",
        "CHECKPOINT_DIR = BASE_DIR / 'checkpoints'\n",
        "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
        "BEST_MODEL_PATH = CHECKPOINT_DIR / 'resnet50_best.pth'\n",
        "print(f'Checkpoint dir: {CHECKPOINT_DIR}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4372ee7a",
      "metadata": {},
      "source": [
        "## 3. 读取 YOLO 标注并构建索引\n",
        "\n",
        "遍历图像文件与对应的 YOLO 标签，记录图片路径、类别名称以及标签中出现的类别 ID。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1efdd3a3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train images: 1770 | Valid images: 30 | Total: 1800\n",
            "Multi-class YOLO annotations: 123 (文件名前缀将作为分类标签)\n",
            "示例: crazing_104.jpg -> [0, 0, 0, 2]\n"
          ]
        }
      ],
      "source": [
        "IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
        "\n",
        "def extract_class_name(image_path: Path) -> str:\n",
        "    return image_path.stem.rsplit('_', 1)[0]\n",
        "\n",
        "def parse_label_file(label_path: Path) -> list:\n",
        "    if not label_path.exists():\n",
        "        return []\n",
        "    ids = []\n",
        "    with open(label_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            parts = line.split()\n",
        "            try:\n",
        "                ids.append(int(parts[0]))\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "    return ids\n",
        "\n",
        "def collect_records(split_name: str, split_root: Path) -> list:\n",
        "    images_dir = split_root / 'images'\n",
        "    labels_dir = split_root / 'labels'\n",
        "    records = []\n",
        "    for img_path in sorted(images_dir.glob('*')):\n",
        "        if img_path.suffix.lower() not in IMAGE_EXTENSIONS:\n",
        "            continue\n",
        "        label_path = labels_dir / f'{img_path.stem}.txt'\n",
        "        yolo_ids = parse_label_file(label_path)\n",
        "        records.append({\n",
        "            'split': split_name,\n",
        "            'image_path': img_path,\n",
        "            'label_name': extract_class_name(img_path),\n",
        "            'yolo_ids': yolo_ids,\n",
        "            'label_path': label_path\n",
        "        })\n",
        "    return records\n",
        "\n",
        "train_records_raw = collect_records('train', TRAIN_ROOT)\n",
        "valid_records_raw = collect_records('valid', VALID_ROOT)\n",
        "all_records = train_records_raw + valid_records_raw\n",
        "print(f'Train images: {len(train_records_raw)} | Valid images: {len(valid_records_raw)} | Total: {len(all_records)}')\n",
        "\n",
        "multi_label_records = [rec for rec in all_records if len(set(rec['yolo_ids'])) > 1]\n",
        "print(f'Multi-class YOLO annotations: {len(multi_label_records)} (文件名前缀将作为分类标签)')\n",
        "if multi_label_records:\n",
        "    sample = multi_label_records[0]\n",
        "    print(f\"示例: {sample['image_path'].name} -> {sample['yolo_ids']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "915db210",
      "metadata": {},
      "source": [
        "## 4. 类别统计\n",
        "\n",
        "依据文件名前缀统计类别分布，并查看 YOLO 标签中出现的主次类别，用于确认映射关系。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bd7f4f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "name_to_id_counts = defaultdict(Counter)\n",
        "for rec in all_records:\n",
        "    for cls_id in rec['yolo_ids']:\n",
        "        name_to_id_counts[rec['label_name']][cls_id] += 1\n",
        "\n",
        "summary_rows = []\n",
        "for name, counter in name_to_id_counts.items():\n",
        "    total = sum(counter.values())\n",
        "    if total:\n",
        "        top_id, top_count = counter.most_common(1)[0]\n",
        "        top_ratio = top_count / total\n",
        "    else:\n",
        "        top_id, top_ratio = None, 0.0\n",
        "    sample_count = sum(1 for rec in all_records if rec['label_name'] == name)\n",
        "    summary_rows.append({\n",
        "        'class_name': name,\n",
        "        'preferred_yolo_id': top_id,\n",
        "        'top_id_ratio': round(top_ratio, 4),\n",
        "        'samples': sample_count\n",
        "    })\n",
        "summary_df = pd.DataFrame(summary_rows).sort_values('preferred_yolo_id')\n",
        "display(summary_df)\n",
        "\n",
        "counts_df = pd.DataFrame({\n",
        "    'split': [rec['split'] for rec in all_records],\n",
        "    'class_name': [rec['label_name'] for rec in all_records]\n",
        "})\n",
        "distribution = counts_df.groupby(['split', 'class_name']).size().unstack(fill_value=0)\n",
        "display(distribution)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8e4214d5",
      "metadata": {},
      "source": [
        "## 5. 构建训练 / 验证 / 测试划分\n",
        "\n",
        "将所有样本按 7:2:1 比例做分层划分，确保各类别在不同子集中的占比接近。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b6b5818",
      "metadata": {},
      "outputs": [],
      "source": [
        "id_name_pairs = []\n",
        "for _, row in summary_df.iterrows():\n",
        "    if row['preferred_yolo_id'] is not None:\n",
        "        id_name_pairs.append((int(row['preferred_yolo_id']), row['class_name']))\n",
        "id_name_pairs = sorted(id_name_pairs, key=lambda x: x[0])\n",
        "class_names = [name for _, name in id_name_pairs]\n",
        "class_to_idx = {name: idx for idx, name in enumerate(class_names)}\n",
        "idx_to_class = {idx: name for name, idx in class_to_idx.items()}\n",
        "print(f'Class order: {class_names}')\n",
        "\n",
        "ratios = (0.7, 0.2, 0.1)\n",
        "train_ratio, val_ratio, test_ratio = ratios\n",
        "assert abs(sum(ratios) - 1.0) < 1e-6\n",
        "\n",
        "indices = np.arange(len(all_records))\n",
        "labels = np.array([class_to_idx[rec['label_name']] for rec in all_records])\n",
        "train_idx, temp_idx = train_test_split(\n",
        "    indices,\n",
        "    test_size=val_ratio + test_ratio,\n",
        "    stratify=labels,\n",
        "    random_state=SEED,\n",
        ")\n",
        "temp_labels = labels[temp_idx]\n",
        "val_fraction = val_ratio / (val_ratio + test_ratio)\n",
        "val_idx, test_idx = train_test_split(\n",
        "    temp_idx,\n",
        "    test_size=1 - val_fraction,\n",
        "    stratify=temp_labels,\n",
        "    random_state=SEED,\n",
        ")\n",
        "\n",
        "def select_records(base, idxs):\n",
        "    return [base[i] for i in idxs]\n",
        "\n",
        "train_records = select_records(all_records, train_idx)\n",
        "val_records = select_records(all_records, val_idx)\n",
        "test_records = select_records(all_records, test_idx)\n",
        "\n",
        "def attach_label_idx(records):\n",
        "    for rec in records:\n",
        "        rec['label_idx'] = class_to_idx[rec['label_name']]\n",
        "\n",
        "attach_label_idx(train_records)\n",
        "attach_label_idx(val_records)\n",
        "attach_label_idx(test_records)\n",
        "\n",
        "print(f\"Train: {len(train_records)} | Val: {len(val_records)} | Test: {len(test_records)}\")\n",
        "for split_name, records in [('Train', train_records), ('Val', val_records), ('Test', test_records)]:\n",
        "    counter = Counter([rec['label_name'] for rec in records])\n",
        "    print(f\"{split_name} per class: {dict(counter)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a655f41",
      "metadata": {},
      "source": [
        "## 6. Dataset 与 DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0d19ed2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataloaders ready -> batches: train=40, val=12, test=6\n"
          ]
        }
      ],
      "source": [
        "class YoloClassificationDataset(Dataset):\n",
        "    \"\"\"基于 YOLO 标注的分类数据集。\"\"\"\n",
        "    def __init__(self, records, transform=None):\n",
        "        self.records = list(records)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        record = self.records[idx]\n",
        "        image = Image.open(record['image_path']).convert('RGB')\n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        label = record['label_idx']\n",
        "        return image, label\n",
        "\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "NUM_WORKERS = 0  # 多进程在 Notebook 中易触发 pickling 报错\n",
        "PIN_MEMORY = DEVICE.type == 'cuda' and NUM_WORKERS > 0\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.2),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "train_dataset = YoloClassificationDataset(train_records, transform=train_transform)\n",
        "val_dataset = YoloClassificationDataset(val_records, transform=eval_transform)\n",
        "test_dataset = YoloClassificationDataset(test_records, transform=eval_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
        "\n",
        "print(f'Dataloaders ready -> batches: train={len(train_loader)}, val={len(val_loader)}, test={len(test_loader)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bba8b073",
      "metadata": {},
      "source": [
        "## 7. 可视化样本\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a0bd392",
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_samples(dataset, num_images=9):\n",
        "    cols = int(num_images ** 0.5)\n",
        "    rows = (num_images + cols - 1) // cols\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
        "    axes = axes.flatten()\n",
        "    for ax in axes:\n",
        "        ax.axis('off')\n",
        "    chosen_indices = np.random.choice(len(dataset), size=min(num_images, len(dataset)), replace=False)\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    for ax, idx in zip(axes, chosen_indices):\n",
        "        image, label = dataset[idx]\n",
        "        image_np = image.numpy().transpose(1, 2, 0)\n",
        "        image_np = image_np * std + mean\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        ax.imshow(image_np)\n",
        "        ax.set_title(idx_to_class[label])\n",
        "    plt.tight_layout()\n",
        "\n",
        "show_samples(train_dataset, num_images=9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "153dde0e",
      "metadata": {},
      "source": [
        "## 8. 创建模型与优化器\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e732a3e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(num_classes: int, dropout: float = 0.3) -> nn.Module:\n",
        "    model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "    in_features = model.fc.in_features\n",
        "    model.fc = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(in_features, num_classes)\n",
        "    )\n",
        "    return model\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "model = create_model(NUM_CLASSES).to(DEVICE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
        "USE_AMP = DEVICE.type == 'cuda'\n",
        "print(model.fc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c1028f5",
      "metadata": {},
      "source": [
        "## 9. 训练与验证函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2b115cd3",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_one_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    progress = tqdm(loader, desc='Train', leave=False)\n",
        "    for images, labels in progress:\n",
        "        images = images.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast(enabled=scaler is not None):\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        running_corrects += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        progress.set_postfix(loss=running_loss / max(total, 1), acc=running_corrects / max(total, 1))\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate(model, loader, criterion, device, return_details=False):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(loader, desc='Eval', leave=False):\n",
        "            images = images.to(device, non_blocking=True)\n",
        "            labels = labels.to(device, non_blocking=True)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "            if return_details:\n",
        "                all_preds.extend(preds.cpu().tolist())\n",
        "                all_labels.extend(labels.cpu().tolist())\n",
        "    epoch_loss = running_loss / total\n",
        "    epoch_acc = running_corrects / total\n",
        "    if return_details:\n",
        "        return epoch_loss, epoch_acc, all_labels, all_preds\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, save_path, use_amp=True):\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
        "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp) if use_amp else None\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print(f'Epoch {epoch}/{num_epochs}')\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device, scaler=scaler)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        print(f\"Train loss: {train_loss:.4f} | acc: {train_acc:.4f}\")\n",
        "        print(f\"Val   loss: {val_loss:.4f} | acc: {val_acc:.4f}\")\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            checkpoint = {\n",
        "                'epoch': epoch,\n",
        "                'model_state': model.state_dict(),\n",
        "                'optimizer_state': optimizer.state_dict(),\n",
        "                'val_acc': val_acc,\n",
        "                'val_loss': val_loss,\n",
        "                'class_names': class_names,\n",
        "                'config': {\n",
        "                    'img_size': IMG_SIZE,\n",
        "                    'mean': [0.485, 0.456, 0.406],\n",
        "                    'std': [0.229, 0.224, 0.225]\n",
        "                }\n",
        "            }\n",
        "            torch.save(checkpoint, save_path)\n",
        "            print(f\"✓ Saved new best model to {save_path} (val_acc={val_acc:.4f})\")\n",
        "    print(f\"Best validation accuracy: {best_acc:.4f}\")\n",
        "    return history\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d5e7d1",
      "metadata": {},
      "source": [
        "## 10. 开始训练\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a40a6f38",
      "metadata": {},
      "outputs": [],
      "source": [
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=DEVICE,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    save_path=BEST_MODEL_PATH,\n",
        "    use_amp=USE_AMP\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 可视化训练曲线\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_history(history_dict):\n",
        "    epochs = range(1, len(history_dict['train_loss']) + 1)\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "    axes[0].plot(epochs, history_dict['train_loss'], label='Train')\n",
        "    axes[0].plot(epochs, history_dict['val_loss'], label='Val')\n",
        "    axes[0].set_title('Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].legend()\n",
        "\n",
        "    axes[1].plot(epochs, history_dict['train_acc'], label='Train')\n",
        "    axes[1].plot(epochs, history_dict['val_acc'], label='Val')\n",
        "    axes[1].set_title('Accuracy')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 加载最优模型并在测试集评估\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_checkpoint = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n",
        "print(f\"Best epoch: {best_checkpoint['epoch']} | Val acc: {best_checkpoint['val_acc']:.4f}\")\n",
        "model.load_state_dict(best_checkpoint['model_state'])\n",
        "test_loss, test_acc, y_true, y_pred = evaluate(model, test_loader, criterion, DEVICE, return_details=True)\n",
        "print(f\"Test loss: {test_loss:.4f} | acc: {test_acc:.4f}\")\n",
        "\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "print(report)\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. 推理函数\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_image(image_path: Path, model: nn.Module, transform, device):\n",
        "    model.eval()\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)\n",
        "        probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
        "    pred_idx = int(np.argmax(probs))\n",
        "    pred_class = idx_to_class[pred_idx]\n",
        "    confidence = float(probs[pred_idx])\n",
        "    return {\n",
        "        'image': image,\n",
        "        'probs': probs,\n",
        "        'pred_class': pred_class,\n",
        "        'confidence': confidence\n",
        "    }\n",
        "\n",
        "def show_prediction(result, title: str = None):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    plt.imshow(result['image'])\n",
        "    plt.axis('off')\n",
        "    caption = title or ''\n",
        "    caption += f\"Pred: {result['pred_class']} ({result['confidence']:.2%})\"\n",
        "    plt.title(caption)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. 推理示例\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_path = Path(test_records[0]['image_path'])\n",
        "print(f'Sample image: {sample_path}')\n",
        "prediction = predict_image(sample_path, model, eval_transform, DEVICE)\n",
        "show_prediction(prediction, title='Test Sample')\n",
        "print('Probability vector:', prediction['probs'])\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (myenv)",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
